{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_signs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktWKcobf3Bj2"
      },
      "source": [
        "**Because our datafile is so large we need to use git lfs before cloning the file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31IERL7v2M9t"
      },
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeeZ5FHh3O17"
      },
      "source": [
        "**clone the repo to access the data files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RageV7kyxoL1"
      },
      "source": [
        "!git clone https://github.com/Cbmunns/Traffic_Sign_Recognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1h3YB1EHdU"
      },
      "source": [
        "**Unzip the large file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcYegWpNDLIt"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!unzip /content/Traffic_Sign_Recognition/sign_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUeyTf6qipmx"
      },
      "source": [
        "**Import important libraries for the file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7cThFRb7kD5"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUWSF2qQiwWT"
      },
      "source": [
        "**Here we set up the lists to hold the data and their respective labels**\n",
        "\n",
        "**Set the number of classes or different number of signs we wish to train on**\n",
        "\n",
        "**Then set the path for or data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-GaRsvJ-RVe"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "classes = 43\n",
        "os.chdir(\"/content\")\n",
        "cur_path = os.getcwd()\n",
        "print(cur_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG3YzmxTjsfw"
      },
      "source": [
        "**Then iterating through each folder, go over every image**\n",
        "\n",
        "**Open the image**\n",
        "\n",
        "**Resize each picture to 30 by 30 for consistency**\n",
        "\n",
        "**Add it to the image list**\n",
        "\n",
        "**And then add it's corresponding label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PySBdfgm-TpO"
      },
      "source": [
        "#Retrieving the images and their labels \n",
        "for i in range(classes):\n",
        "    path = os.path.join(cur_path,'train', str(i))\n",
        "    print(path)\n",
        "    images = os.listdir(path)\n",
        "    #print(images)\n",
        "    for a in images:\n",
        "        try:\n",
        "            image = Image.open(path + '/'+ a)\n",
        "            image = image.resize((30,30))\n",
        "            image = np.array(image)\n",
        "            data.append(image)\n",
        "            labels.append(i)\n",
        "        except:\n",
        "            print(\"Error loading image\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR4-zDezmGMK"
      },
      "source": [
        "**Convert the lists into numpy arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVdBMfS-X1q"
      },
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQec-AWpmctz"
      },
      "source": [
        "**We then get the dimensions of the arrays**\n",
        "\n",
        "**Then seperate into the test/train sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3aDzVxA-a6n"
      },
      "source": [
        "print(data.shape, labels.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKN0NKqqms2o"
      },
      "source": [
        "**Place a quick check on the dimensions of the new arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRRma2HZ-a5x"
      },
      "source": [
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQFdGxkXnRHT"
      },
      "source": [
        "**We then use one hot encoding to break the different labels into easily deciphered binary**\n",
        "\n",
        "For ex.)  \n",
        "**label**  \n",
        "stop,  \n",
        "10,  \n",
        "20,  \n",
        "\n",
        "Becomes.)  \n",
        "**stop  10  20**  \n",
        "1, 0, 0,  \n",
        "0, 1, 0,  \n",
        "0, 0, 1,  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neCSOxPC-ca7"
      },
      "source": [
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZCKZOFNoqQB"
      },
      "source": [
        "**This code is to identify and verify that a GPU is available and what it's label is**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbFu3NJrNrHR"
      },
      "source": [
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUS Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb_k9VU7o_9x"
      },
      "source": [
        "**Using GPU acceleration we build our model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3scfYDF-cUo"
      },
      "source": [
        "with tf.device('/gpu:0'): \n",
        "  #Building the model\n",
        "  model = Sequential()\n",
        "  # We establish our convolutional layers with filter size of 5X5\n",
        "  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
        "  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "  # Max-pooling/down sample the output of this data  of size 2 x 2\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  # Improve the reliability we use dropout to regularize the output and help prevent overfitting\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  # We repeat! now with the filter set to 3 X 3\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "  # Down sample\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  # Regularize\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  # Flatten the data to prepare for the Dense layer\n",
        "  model.add(Flatten())\n",
        "  # Run this through a standard Dense layer\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  # Regularize\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  # Final output layer with all 43 classes represented\n",
        "  model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Fit and store the model with 15 epochs\n",
        "  history = model.fit(X_train, y_train, batch_size=32, epochs= 15, validation_data=(X_test, y_test))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SOgpycuxXmF"
      },
      "source": [
        "**Using the history object we observe the accuracy of our model over time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY6j9MvS-cDO"
      },
      "source": [
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSeE6g6pxyfF"
      },
      "source": [
        "**Again using history we examine the loss of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60cbU66D-cCh"
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n65QxqbyATb"
      },
      "source": [
        "**Using a premade CSV we access shuffled photos that haven't been ran on the model to test true accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_bViqu-svw"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_test = pd.read_csv('Test.csv')\n",
        "labels = y_test[\"ClassId\"].values\n",
        "imgs = y_test[\"Path\"].values\n",
        "data=[]\n",
        "for img in imgs:\n",
        "    image = Image.open(img)    \n",
        "    image = image.resize((30,30))    \n",
        "    data.append(np.array(image))\n",
        "\n",
        "X_test=np.array(data)\n",
        "pred = model.predict_classes(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wPjYA8Qyp6k"
      },
      "source": [
        "**Output the true accuracy of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCRrmug-vo0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels, pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIL6CL2B7eDA"
      },
      "source": [
        "**Base code was used as a learning tool and was sourced from**  \n",
        "https://data-flair.training/blogs/python-project-traffic-signs-recognition/"
      ]
    }
  ]
}